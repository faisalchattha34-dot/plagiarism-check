# -*- coding: utf-8 -*-
"""similaritychecker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K5e8NXe1jWr0WW5XVy_iHxrVLz8C2z7B
"""

import os

from sklearn.feature_extraction.text import TfidfVectorizer

pip install python-docx

from sklearn.metrics.pairwise import cosine_similarity

student_files=[f for f in os.listdir() if f.endswith('.docx')]

student_files

import os
from docx import Document

# Step 1: Get all .docx files in the current directory
student_files = [f for f in os.listdir() if f.endswith('.docx')]

# Step 2: Read text from each .docx file safely
student_notes = []

for file in student_files:
    doc = Document(file)
    text = "\n".join([para.text for para in doc.paragraphs])
    student_notes.append(text)

# Step 3 (optional): Print or use the notes
for i, note in enumerate(student_notes, start=1):
    print(f"--- Document {i}: {student_files[i-1]} ---")
    print(note[:500])  # show only first 500 characters
    print()

student_notes

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(student_notes)

# Compute pairwise similarity between documents
similarity_matrix = cosine_similarity(tfidf_matrix)

print(similarity_matrix)

for i, text in enumerate(student_notes):
    print(f"Summary for {student_files[i]}:")
    # Very basic summary – first 2 lines
    print("\n".join(text.split("\n")[:2]))
    print("-" * 40)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Assume student_notes = [text1, text2, text3, ...]
# and student_files = ['a.docx', 'b.docx', 'c.docx']

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(student_notes)

# Compute pairwise similarity between all documents
similarity_matrix = cosine_similarity(tfidf_matrix)

# Print the matrix (optional)
print("Similarity Matrix:")
print(similarity_matrix)

# Example: check similarity between two specific docs
i, j = 0, 1  # indices of the documents you want to compare
similarity_score = similarity_matrix[i][j]

print(f"\nSimilarity between '{student_files[i]}' and '{student_files[j]}' is: {similarity_score:.2f}")

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(similarity_matrix, annot=True, xticklabels=student_files, yticklabels=student_files, cmap="YlGnBu")
plt.title("Document Similarity Heatmap")
plt.show()

import pandas as pd

df = pd.DataFrame(similarity_matrix, index=student_files, columns=student_files)
df.to_csv("similarity_results.csv")

print("✅ Similarity results saved to similarity_results.csv")

import pandas as pd
data=pd.read_csv("/content/similarity_results.csv")
data